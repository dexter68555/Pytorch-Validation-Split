{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****## Split dataset into training and validation (Pytorch)\n",
    "\n",
    "In this notebook I'm showing how to split validation set from training set that will have reproducible results.\n",
    "I found out that not everyone knows how to do this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be all the library used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torch.utils import data as D\n",
    "\n",
    "import time\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "from IPython.display import display\n",
    "\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be all the function used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "\n",
    "    # override the __getitem__ method. this is the method dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path\n",
    "    \n",
    "    \n",
    "'''\n",
    "This part train resnet model with default 10 epoch.\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, n_epochs = 10):\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    test_accuracies = []\n",
    "    tmp_acc = 0.0\n",
    "    # set the model to train mode initially\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        since = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            # get the inputs and assign them to cuda\n",
    "            inputs, labels, _ = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # calculate the loss/acc later\n",
    "            running_loss += loss.item()\n",
    "            running_correct += (labels==predicted).sum().item()\n",
    "\n",
    "        epoch_duration = time.time()-since\n",
    "        epoch_loss = running_loss/len(trainloader)\n",
    "        epoch_acc = 100/32*running_correct/len(trainloader)\n",
    "        print(\"Epoch %s, duration: %d s, loss: %.4f, acc: %.4f\" % (epoch+1, epoch_duration, epoch_loss, epoch_acc))\n",
    "        \n",
    "        losses.append(epoch_loss)\n",
    "        accuracies.append(epoch_acc)\n",
    "        \n",
    "        # switch the model to eval mode to evaluate on test data\n",
    "        model.eval()\n",
    "        test_acc = evaluate_model(model)\n",
    "        test_accuracies.append(test_acc)\n",
    "        \n",
    "        '''\n",
    "        This will save the best model in training.\n",
    "        '''\n",
    "        if test_acc > tmp_acc:\n",
    "            tmp_acc = test_acc\n",
    "            torch.save(model, \"../working/model.pth\")\n",
    "        \n",
    "        # re-set the model to train mode after validating\n",
    "        model.train()\n",
    "        scheduler.step(test_acc)\n",
    "        since = time.time()\n",
    "        \n",
    "    model.eval()\n",
    "    get_predict(model)\n",
    "    print('Finished Training')\n",
    "    model.train()\n",
    "    return model, losses, accuracies, test_accuracies\n",
    "\n",
    "'''\n",
    "This part evaluation the model every epoch with validation dataset.\n",
    "'''\n",
    "def evaluate_model(model):\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validloader, 0):\n",
    "            images, labels, _ = data\n",
    "            #images = images.to(device).half() # uncomment for half precision model\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model_ft(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_acc = 100.0 * correct / total\n",
    "    print('Accuracy of the network on the validation images: %.2f %%' % (\n",
    "        test_acc))\n",
    "    return test_acc\n",
    "\n",
    "'''\n",
    "This part will get the prediction result from the model.\n",
    "The result include confidence result and also the best confidence result.\n",
    "'''\n",
    "\n",
    "def get_predict(model):\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            images, labels, fnames = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model_ft(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            tmp_predict = outputs.data\n",
    "            predicted2 = torch.nn.functional.softmax(tmp_predict)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_acc = 100.0 * correct / total\n",
    "    print('Accuracy of the network on the testing images: %.2f %%' % (\n",
    "        test_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and transform\n",
    "\n",
    "First, lets create some transforms for our data and load the train/validation and test data with labels from the folders.\n",
    "\n",
    "Here I use 400 x 400 images with random horizontal flip, random rotation and normalization.\n",
    "\n",
    "I used 400 x 400 due to the limitation of computer resources. \n",
    "\n",
    "400 x 400 is the maximum resolution that I can run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Manual seed everything to get reproducible results\n",
    "'''\n",
    "SEED = 123\n",
    "seed_everything(SEED)\n",
    "\n",
    "'''\n",
    "This is the dataset directory for my Kaggle kernel. \n",
    "Please comment this line and uncomment the following line if you run it on your workstation.\n",
    "'''\n",
    "dataset_dir = \"../input/car_data/car_data/\"\n",
    "\n",
    "\n",
    "train_tfms = transforms.Compose([transforms.Resize((400, 400)),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.RandomRotation(15),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "test_tfms = transforms.Compose([transforms.Resize((400, 400)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "dataset = ImageFolderWithPaths(root=dataset_dir+\"train\", transform = train_tfms)\n",
    "\n",
    "'''\n",
    "This is the part that will split validation set from training set.\n",
    "This part I load image from folder and then split 90% for training and 10% for validation.\n",
    "The label will be the sub folder of each image.\n",
    "'''\n",
    "train_len = int(0.9 * 8144)\n",
    "valid_len = 8144 - train_len\n",
    "\n",
    "#Pytorch had provided a function called random_split but this will only randomly split dataset without reproducible results\n",
    "#There is no seed argument for this function so I had to manual set seed \n",
    "\n",
    "train_dataset, valid_dataset = D.random_split(dataset, lengths=[train_len, valid_len])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size = 32, shuffle=True, num_workers = 2)\n",
    "\n",
    "validloader = torch.utils.data.DataLoader(valid_dataset, batch_size = 32, shuffle=True, num_workers = 2)\n",
    "\n",
    "test_dataset = ImageFolderWithPaths(root=dataset_dir+\"test\", transform = test_tfms)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size = 32, shuffle=False, num_workers = 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training function\n",
    "\n",
    "Here I start to train my model with validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /tmp/.cache/torch/checkpoints/resnet50-19c8e357.pth\n",
      "100%|██████████| 102502400/102502400 [00:00<00:00, 103294985.02it/s]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This will download pretrained torch model from internet.\n",
    "'''\n",
    "model_ft = models.resnet50(pretrained=True)\n",
    "\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "# replace the last fc layer with an untrained one (requires grad by default)\n",
    "model_ft.fc = nn.Linear(num_ftrs, 196)\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "\"\"\"\n",
    "probably not the best metric to track, but we are tracking the training accuracy and measuring whether\n",
    "it increases by atleast 0.9 per epoch and if it hasn't increased by 0.9 reduce the lr by 0.1x.\n",
    "However in this model it did not benefit me.\n",
    "\"\"\"\n",
    "lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, duration: 153 s, loss: 4.2294, acc: 12.6766\n",
      "Accuracy of the network on the validation images: 26.13 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:137: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the testing images: 27.35 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model_ft, training_losses, training_accs, test_accs = train_model(model_ft, criterion, optimizer, lrscheduler, n_epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
